{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, jaccard_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform, loguniform\n",
    "from scipy.stats import randint\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Between Binary Relevance Approach and Classifier Chains Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the binary relevance approach, a multi-classification problem is broken down into multiple binary classification sup-problems by creating a classifier for each label. On the other hand, in the classifier chains approach, a sequence of binary classifiers are created but, unlike the binary relevance approach, the classifiers are not independent as predictions from the previous classifiers are used as inputs for the next classifier. This means that the binary relevance approach is simpler and less computationally expensive than the classifier chains approach. However, the classifier chains approach can capture label correlations better than the binary relevance approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining a Multi-Label Classifier Using the Binary Relevance Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Accuracy: 0.1405\n",
      "Hamming Loss: 0.1926\n",
      "Jaccard Score: 0.5087\n",
      "F1 Score: 0.6210\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('yeast.csv')\n",
    "\n",
    "data.drop(0)\n",
    "X = data.iloc[:, :103].values \n",
    "y = data.iloc[:, 103:].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create a base classifier\n",
    "base_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers\n",
    "    activation='relu',             # ReLU activation function\n",
    "    solver='adam',                 # Adam optimizer\n",
    "    max_iter=300,                  # Maximum iterations\n",
    "    random_state=42,               # For reproducibility\n",
    "    early_stopping=True,           # Enable early stopping\n",
    "    validation_fraction=0.1        # Use 10% of training data for validation\n",
    ")\n",
    "\n",
    "# Create and train the binary relevance classifier\n",
    "binary_relevance = BinaryRelevance(\n",
    "    classifier=base_classifier,\n",
    "    require_dense=[True, True]     # Both X and y should be dense matrices\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "binary_relevance.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = binary_relevance.predict(X_test)\n",
    "\n",
    "# Convert sparse matrix predictions to dense array for evaluation\n",
    "y_pred_dense = y_pred.toarray()\n",
    "y_test_dense = y_test\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_binary = accuracy_score(y_test_dense, y_pred_dense)\n",
    "hamming_binary = hamming_loss(y_test_dense, y_pred_dense)\n",
    "jaccard_score_binary = jaccard_score(y_test_dense, y_pred_dense, average='samples')\n",
    "f1_score_binary = f1_score(y_test_dense, y_pred_dense, average='samples')\n",
    "\n",
    "print(f\"Subset Accuracy: {accuracy_binary:.4f}\")\n",
    "print(f\"Hamming Loss: {hamming_binary:.4f}\")\n",
    "print(f\"Jaccard Score: {jaccard_score_binary:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_binary:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Accuracy: 0.2314\n",
      "Hamming Loss: 0.2050\n",
      "Jaccard Score: 0.5205\n",
      "F1 Score: 0.6136\n"
     ]
    }
   ],
   "source": [
    "# Create a base classifier\n",
    "base_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers\n",
    "    activation='relu',             # ReLU activation function\n",
    "    solver='adam',                 # Adam optimizer\n",
    "    max_iter=300,                  # Maximum iterations\n",
    "    random_state=42,              # For reproducibility\n",
    "    early_stopping=True,          # Enable early stopping\n",
    "    validation_fraction=0.1       # Use 10% of training data for validation\n",
    ")\n",
    "\n",
    "# Create and train the classifier chain\n",
    "classifier_chain = ClassifierChain(\n",
    "    classifier=base_classifier,\n",
    "    require_dense=[True, True],    # Both X and y should be dense matrices\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "classifier_chain.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier_chain.predict(X_test)\n",
    "\n",
    "# Convert sparse matrix predictions to dense array for evaluation\n",
    "y_pred_dense = y_pred.toarray()\n",
    "y_test_dense = y_test\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_chains = accuracy_score(y_test_dense, y_pred_dense)\n",
    "hamming_chains = hamming_loss(y_test_dense, y_pred_dense)\n",
    "jaccard_score_chains = jaccard_score(y_test_dense, y_pred_dense, average='samples')\n",
    "f1_score_chains = f1_score(y_test_dense, y_pred_dense, average='samples')\n",
    "\n",
    "print(f\"Subset Accuracy: {accuracy_chains:.4f}\")\n",
    "print(f\"Hamming Loss: {hamming_chains:.4f}\")\n",
    "print(f\"Jaccard Score: {jaccard_score_chains:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_chains:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapted algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Hyperparameters to Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first hyperparameters chosen to optimize are the number of hidden layers and the number of neurons in each layer. The hidden layer size can impact the model's ability to model the data, which is especially in a multi-label dataset as the model needs to be able to learn the relationships between the inoput features and the multiple labels. Finding the optimal number of hidden layers and neurons is important as it ensures that the model as too few neurons can lead to underfitting, while too many neurons can lead to overfitting.\n",
    "\n",
    "Another hyperparameter that is selected for optimization is the learning rate. The learning rate is important as it determines how the model learns its weights. If the learning rate is too high it may overshoot the optimal values and fail to converge. On the other hand, if the learning rate is too low, the model may take a long time to converge or may get stuck in a local minimum. Therefore, performing hyperparameter optimization on the learning rate can help to find the optimal learning rate for the model such that learning is balanced between all the labels.\n",
    "\n",
    "Alpha is another hyperparameter that is selected for optimization. Alpha is the L2 regularization parameter that is used to prevent overfitting. This is especially important for datasets with a large number of features as they are more prone to overfitting and in datasets with multiple labels as to prevent the model from overfitting to one label. \n",
    "\n",
    "Lastly, the batch size is selected for optimization. Batch size is the number of samples that are used to update the model's weights. Small batch sizes can lead to better generalization and but can be computationally expensive. On the other hand, large batch sizes can lead to faster training times but can lead to poor generalization. Finding the optimal batch size is important in a multi-label dataset as the batch size needs to be large enough to contain enough label combinations while also being small enough to prevent overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting an HPO Technique Supported By the `scikit-learn` Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen HPO technique is random search. Random search is chosen as it is more computational efficient, especially in the case for large datsets since it randomly samples the search space instead of exploring every possible parameter combination. Additionally, randoms search allows for continuous hyperparameters to be optimized. This is useful when optimizing hyperparameters such as learning rates and alpha as it allows us to find more accurate values for these hyperparameters. Lastly, random search is better able to explore the search space and find important hyperparameters when compared to grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Suitable Value of ùêæ for Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of K chosen for ùêæ-foldcross-validation is 5. 5 was chosen as it ensures we have enough data for training and validation. While choosing a larger value of K could be more benifificial since each fold will train on more data it would also be more computationally expensive. Additonally, the dataset is large and therefore each fold will have enough training samples and will contain suffienct examples for all of the 14 labels despite the smaller value of K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining a Neural Network Multi-Label Classifier Using HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'alpha': np.float64(0.006187670675880952), 'batch_size': 32, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': np.float64(0.004895834359555106)}\n",
      "\n",
      "Best cross-validation score: 0.6233\n",
      "\n",
      "Test Set Performance:\n",
      "Subset Accuracy: 0.1839\n",
      "Hamming Loss: 0.1942\n",
      "Jaccard Score: 0.5323\n",
      "F1 Score: 0.6367\n",
      "\n",
      "Output layer activation function:\n",
      "logistic\n"
     ]
    }
   ],
   "source": [
    "# Define parameter distributions \n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,25), (100,50), (100,50,25)],\n",
    "    'learning_rate_init': loguniform(1e-4, 1e-1),\n",
    "    'alpha': loguniform(1e-4, 1e-2),\n",
    "    'batch_size': [32, 64, 128, 256, 'auto']\n",
    "}\n",
    "\n",
    "# Create base neural network \n",
    "base_nn = MLPClassifier(\n",
    "    activation='relu',           # ReLU for hidden layers\n",
    "    solver='adam',              \n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Configure RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_nn,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=5,                      # 5-fold cross-validation as discussed\n",
    "    scoring='f1_samples',      # F1 score for multi-label classification\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Perform hyperparameter optimization\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(random_search.best_params_)\n",
    "print(f\"\\nBest cross-validation score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_hpo = accuracy_score(y_test, y_pred)\n",
    "hamming_hpo = hamming_loss(y_test, y_pred)\n",
    "jaccard_score_hpo = jaccard_score(y_test, y_pred, average='samples')\n",
    "f1_score_hpo = f1_score(y_test, y_pred, average='samples')\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"Subset Accuracy: {accuracy_hpo:.4f}\")\n",
    "print(f\"Hamming Loss: {hamming_hpo:.4f}\")\n",
    "print(f\"Jaccard Score: {jaccard_score_hpo:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_hpo:.4f}\")\n",
    "\n",
    "# Print information about the neural network's last layer\n",
    "print(\"\\nOutput layer activation function:\")\n",
    "print(best_model.out_activation_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is adapted so that its outputs are suitable for multi-label classification since `MLPClassifier` automatically adapts for multi-label classification by using a sigmoid function at the output layer. This can be seen in the code above when printinting the output layer activation function, which is a logistic (sigmoid) function. The sigmoid function is important as it allows each neuron to make independent predictions between 0 and 1, which is important for multi-label classification as each label can be predicted independently of the others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
